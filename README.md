## Common Interview Q&A

**消息队列**

1. MQ的主要有哪些作用(包括使用场景)

   异步、削峰填谷、解耦

2. MQ的技术选型

3. MQ如何保证高可用性

4. MQ的重复消费该如何解决

   * 在下游消费者接口中保持幂等性，即使消息重复也不会有问题

5. MQ的消息丢失该如何解决

   * 生产者消息丢失：启用mq ack配置，当mq回馈确认消息成功才算发送成功，否则就进行重试。
   * mq消息丢失：开启mq持久化消息配置。kafka可以设置整个集群确认同步后才返回ack，否则就无限重试。
   * 消费者消息丢失：配置手动提交offset，消费失败则mq重发，直到接收到消费者的ack。

6. MQ的消息顺序性如何保证

   * 消费者使用一个partition/ queue进行消费，并按一定的规则把需要保证顺序的数据路由到特定的partition/queue中，由单独的一个消费者消费。

7. MQ的架构设计

   

**分布式缓存**

1. redis和memcache的区别

2. redis的线程模型

   单线程IO多路复用

3. redis支持哪些数据结构

   String、Set、List、Zset、hash

4. redis的过期策略

5. 如何保证redis的高可用

6. redis的主从复制

7. redis的哨兵机制

8. redis的持久化方式

   * aof 通过记录操作日志来进行持久化
   * rdb 通过直接记录缓存中的数据来进行持久化

9. LRU算法

10. 数据库与缓存双写一致性
    * Cache Aside Pattern，读数据的时候，先从缓存中读取，缓存中不存在，则再从数据库中读取，并插入到缓存中。更新缓存时，先删除缓存，再更新数据库。如果先更新数据库的话，若之后删除缓存失败，会导致后面的请求读到的数据仍然是旧的。为什么不是更新缓存而是删除缓存，因为如果更新缓存的话，假如写操作的频率非常高，那么更新缓存的频率也非常高，而在此期间读操作可能只有一次，改成删除操作的话，那么只有在读这一次的时候才会更新缓存，大大降低了缓存的更新频率。在高并发环境下，当写操作未完成数据库更新时，由于读操作的线程未命中缓存，读取了数据库中的旧值，并更新到了缓存中，导致数据过期。这种情况下，需要在内存中维护一个更新队列，将写操作和读操作全部放入，并一一执行，即可保证一致性，
    * 优化点：对同一对象的多个读操作的更新请求可以合并。
    * 缺点：写操作数量庞大的时候可能导致读操作长时间阻塞。

**API网关的设计**

1. 网关的使用场景
2. 网关设计需要考虑的因素
   * 负载均衡
   * 限流
   * 黑名单
   * 路由
   * 监控



**数据库相关**

1. 数据库引擎MyIsam和InnoDB的区别

   innodb支持事务，支持外键，使用聚集索引，支持行级锁，innodb要求表必须有主键，如果没有主键则会生成一个6字节的rowid，innodb的索引和数据都存放在叶子节点。InnoDB不仅缓存索引信息，还会缓存数据信息。其将数据文件按页读取到缓冲池，然后按最近LRU算法来更新数据。

   myisam不支持事务，不支持外键，使用非聚集索引，支持表级锁，myisam的索引和数据是分离的。

2. 分库分表
   * 水平拆分
   * 垂直拆分
   * 分库分表的数据迁移
   * 相关的中间件：Mycat, sharding-jdbc

3. 分库分表后id主键的生成策略

   - 对外提供服务的算法：使用snowflake算法：时间戳+机房号+机器号+序列号；

   - 客户端生成的算法： mongodb的ObjectId生成算法：Unix时间戳+机器号+进程号+随机数。无锁，使用CAS来保证数据不重复。

     以上两种算法都是单机递增，全局唯一

4. 慢查询优化

5. mvcc

   在InnoDB中，每一行都有2个隐藏列DATA_TRX_ID和DATA_ROLL_PTR

   当sql语句在执行时会产生一个ReadView，ReadView中存储了事务链表中的最小事务uid和最大事务lid。当隔离级别为rr时，该事务链表中的所有数据都是不可见的，uid和lid保持一致即可。当隔离级别为rc时，uid和lid的所有数据对其都是可见的。

6. 数据库的三大范式

   * 所有字段均不可再次拆分。
   * 建立在第一范式的基础上，所有字段必须依赖于主键
   * 任何非主属性不得依赖于其他的非主键属性

7. 数据库异构

8. 字段冗余设计方案

9. 如何实现数据查询时加锁

   在SELECT语句中添加FOR UPDATE，即给需要读取的数据添加排他锁，等待更新事务完成后读取其最新内容。

10. 事务的隔离级别

    * read committed 可以读取到当前资源的最新commit数据
    * repeatable read 当事务开始后，该事务读取到的数据始终是不变的，即其他线程的事务操作对该事务不可见。
    * read uncommit 可获取其他事务未提交的数据，会产生脏读，一般不使用。(除非使用场景对性能的要求很高，并且可以容忍脏读)
    * serialize 最高隔离级别，串行读写，读写会互相阻塞

11. ACID

    * A：atomic 原子性
    * C：consistency 一致性
    * I：isolation  隔离性
    * D: duration 持久性

12. 幻读、脏读、不可重复读

    * 幻读：由于其他事务的更新操作，在某次事务中的对同一资源的两次读取结果的数量不一样（针对insert和delete）。
    * 脏读：读取到了其他事务未提交的数据
    * 不可重复读：由于其他事务的更新操作，在某次事务中的对同一资源的两次读取结果不一样（针对update）。



**JVM相关**

1. 类加载机制

2. 几种常见的垃圾回收器G1，CMS等

3. 垃圾回收算法：标记清除，复制算法，标记整理算法

4. JVM的内存模型

   线程共享的有：堆内存，方法区(元空间)

   线程私有：虚拟机栈，本地方法栈，程序计数器

5. 双亲委派模型

   * 当类加载器加载类的时候，首先会将该类委托给父类进行加载，如果父类加载不了，再由自己进行加载。这样的好处是可以保证jvm中的类不被外部的同名类侵染，有利于虚拟机安全。
   * jdk提供了三种类加载器，BootstrapClassLoader，ExtentionClassLoader，AppClassLoader。前两种类加载器分别用于加载jvm基础类和扩展类，第三种才是用于加载用户定义的类。
   * 双亲委派模型的破坏：tomcat破坏了双亲委派模型：1. 为了加载同一个类的不同版本；2. 为了jsp的热更新热部署。一般的破坏实现方式是在Thread中设置自定义的contextClassLoader。

6. 当执行 ``` Test test = new Test() ``` 的时候，发生了什么？

   * 首先jvm会去查找Test类是否已经加载，如果没有则加载Test类
   * 在确认类已经加载完成后，jvm对该对象进行内存分配，主要有两种方式：
     * 指针碰撞：适用于内存比较规整的情况，jvm维护了一个用于指示已使用内存和空闲内存的指针，此时会将空闲一侧的内存分配出来。
     * 空闲列表：jvm维护了一个内存碎片的列表，此时会将大小合适的内存碎片分配出来；
     * 对于对象并发创建时，有两种方案，CAS和TLAB，TLAB是在Eden预留了一部分内存空间，当预留空间不足时，再进行CAS分配内存。
   * 在完成内存分配后，jvm对test对象设置零值
   * 在设置零值完成后，jvm开始设置对象头：包括锁信息，hash值，类信息
   * 在对象头设置完成后，执行init方法（由开发人员编写的逻辑）。





**数据结构与算法相关**

1. 快速排序算法的实现

   首先，选定任意一个节点，将比其小的数据放到其左边，将比其大的数据放到右边。将此称为一次排序。

   然后再对左边和右边的数据分别进行上述排序，直至整个数组排序完成。

2. 希尔排序的实现

3. 红黑树，二叉树相关的原理

4. 跳表的相关原理和实现

   跳表最底层维护了所有数据的链表，每高一级大约减少一半（由插入时的高阶节点生成算法决定）的数据，每个节点都有指向下一级的指针，它多存储了一倍的空间，时间复杂度约为log(n)

5. B树和B+树

6. Mysql的存储结构为何选择B+树而不是B树或者二叉树？

   二叉树的查询效率很高，时间复杂度为O(log(n))，但是由于其节点数只有2，当数据量非常庞大的时候，树的深度会非常深，一旦查询深度过深，需要多次重新定位文件，导致查询效率低下。B树解决了树深度过深的问题，而且它的数据直接存储在每个节点中，但是需要遍历数据时必须进行中序遍历，导致效率低下。B+树的非叶子节点只存储索引，所有数据都存储在叶子节点中，且每个叶子节点都有指向下一个叶子节点的指针，当需要对数据进行遍历时，只要遍历叶子节点即可。



**java基础**

1. HashMap的原理

2. JUC相关工具

   1. ConcurrentHashMap

      1.7中使用segment分段锁。每个segment都持有一部分bucket，在初始化的时候可以指定segment的数量，但是之后不支持segment数组扩容。ConcurrentHashMap的扩容就是对segment内部的bucket进行扩容，每次扩大一倍。

      1.8中使用Entry为锁，扩容时采用多段多线程分别扩容（也有可能最终执行扩容的是同一个线程）的方法（transfer）。

   2. CountDownLatch

      这是一个异步转同步的工具，通过一个总的任务计数递减来控制异步转同步的时机。

3. List，Set

4. 线程池的原理和执行流程

5. synchronize的三种锁

   * 偏向锁：该等级的锁认为只有一个线程会来获取和执行，在线程第一次进入的时候会通过cas来设置锁标记，并设置线程id，执行完成后不会更改；当线程第二次进入时，如果发现当前线程id和自己相同，则不再更改所标记，直接进入执行。如果发现线程id不同，则升级为轻量级锁。

   * 轻量级锁：该等级的锁在线程进入时会通过cas来设置锁标记，退出时再通过cas将锁标记取消。如果cas失败，则会升级为重量级锁。适用于多线程执行时间错开的场景。

   * 重量级锁：该等级的锁在线程进入时，如果无法获取到锁，便会立刻进入阻塞状态，等待持有该锁的其他线程唤醒。

6. synchronize和ReentrantLock，死锁产生的场景

7. jdk1.8中的新api（Optional，Stream，lamda表达式等等）

8. AQS(抽象队列同步)

9. IO，NIO，BIO相关

10. IO多路复用

11. volatile关键字的底层实现

12. ThreadLocal类的使用与原理

13. HashMap在并发环境下可能会出现什么问题

    可能会出现环形链表，HashMap在进行rehash的时候，如果发生了扩容，会将一个bucket里面的链表进行重新分发。分发后的链表顺序会倒置（1.7，1.8版本的jdk是在链表末端插入元素的）。如果有两个线程同时进行rehash，查阅源码
    ``` java
    do {
        Entry<K,V> next = e.next; // <--假设线程一执行到这里就被调度挂起了
        int i = indexFor(e.hash, newCapacity);
        e.next = newTable[i];
        newTable[i] = e;
        e = next;
    } while (e != null);
    ```

    可知，在此过程中维护了两个指针e和next，导致了环形链表的出现。

14. aba问题

    在cas过程中可能会出现aba问题，解决方法是在更新的时候对数据添加版本号。AtomicMarkableReferencek就提供了这样的功能。

15. volatile为何不能保证原子性

    volatile++其实执行了三步操作：1. 从主内存中读取数据到工作内存；2. 对数据进行自增处理；3. 将数据写回到主内存。当两个线程都执行完了第二步的时候，此时线程1先将数据写回到主内存，但线程2已经完成了自增操作，不会再从主内存中读取最新数据，于是便会将无效的数据写到主内存中。



**框架相关**

1. Spring的生命周期
2. Spring的核心，IOC和AOP
3. Spring用到的设计模式
   * 单例模式
   * 抽象工厂
   * 样板方法
   * 观察者模式
   * 代理模式
4. Spring是如何解决循环引用的 ？
5. Springboot和Spring的对比
6. Springboot的内置web容器
7. Springboot的思想：约定大于配置
8. SpringCloud的注册中心
9. SpringCloud的配置中心
10. SpringCloud的网关
11. SpringCloud的熔断器
12. Dubbo相关知识
    * Dubbo的服务调用依赖于底层的RpcProxy，默认使用netty，性能高于基于Http调用的SpringCloud。

    * Dubbo的十层架构：
      1. service：由用户实现的接口层
      2. config：Provider和Consumer的配置
      3. proxy：代理生成的Proxy和Invoker类(实际的调用方和被调用方)
      4. registry：封装服务地址的注册与发现
      5. cluster：封装多个提供者的路由及负载均衡，并桥接注册中心
      6. monitor：RPC调用次数和调用时间监控
      7. protocol：封装RPC调用，以Invocation和Result为中心
      8. exchange：封装请求响应模式，同步转异步
      9. transport：抽象mina和netty为统一接口，以Message为中心
      10. serialize：封装序列化的方式

    * Dubbo的服务治理：

      1. 服务调用链路
      2. 服务降级
      3. 服务鉴权
      4. 服务监控
      5. 服务的超时重试

    * Dubbo的SPI扩展

      实现Dubbo提供的SPI接口后，打成jar包，放到META-INF/services/下面并配置key=com.xxx.xxx.xxx，在调用代码中配置相关的key，即可实现Dubbo的SPI扩展

**分布式相关**

1. CAP理论以及相关实践

2. BASE理论

3. 分布式事务XA，2PC，3PC，TCC，本地消息表
   * XA：单机对处于同一事务的多种资源处理时使用，在执行业务逻辑前打开所有资源的事务，成功后统一commit，失败则全部rollback。
   * 2PC：分为prepare和commit两个阶段，prepare阶段协调者会询问参与者是否可以提交，参与者认为可以则将undo和redo信息写到事务日志中。commit阶段一旦任意参与者失败则协调者调用undo进行rollback，缺点：所有回滚逻辑均需要手动实现，非常麻烦，且存在参与者阻塞协调者的问题。
   * 3PC：分为canCommit，preCommit，doCommit三个阶段，参与者在preCommit阶段将undo和redo信息写入到事务日志中。在doCommit阶段出现异常则协调者调用undo进行rollback。缺点：所有回滚逻辑均需要手动实现，非常麻烦。协调者如果宕机，在一定时间内参与者会自动提交事务
   * 本地消息表：在系统A持久化业务数据的同时插入一个本地消息表并置为待消费状态，同时通过mq发送消息给系统B，消息B消费完成后回调系统A的通知接口(或可以使用zookeeper做监听)，将消息置为已消费状态。系统A需要维护一个轮询待消费状态消息的线程，将超时待消费消息重新发给B进行消费，如果多次后仍然失败，需要进行回滚。系统B必须保证消息消费的幂等性。

4. 使用redis实现的分布式锁，会有什么问题？

   1. setnx和expire的非原子性

      使用LUA脚本

   2. 超时后使用del 导致误删其他线程的锁

      在获取锁时存入当前的线程id，删除时判断是否为自己线程所持有的锁。(原子性问题可以用LUA脚本解决) 如下：
      ``` lua
      if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end 
      ```

   3. 由于超时时间的设置，仍然存在出现并发的可能性

   



**运维相关**

1. docker的概念和使用
2. Linux的常用指令



**高并发相关**

1. 如何设计一个高并发的系统？
   * 拆分系统，将系统根据业务拆分成多个模块，对压力较大的模块做集群；
   * 使用分布式缓存，缓解数据库压力
   * 使用MQ进行削峰
   * 动静资源分离
   * 数据库读写分离
   * 使用分布式搜索引擎



**网络相关**

1. http的三次握手和四次挥手
2. 当我们在浏览器访问一个网址的时候，发生了什么



**线上故障排查相关**

1. cpu 100%

   使用jstack工具dump出问题的服务器的栈信息，死循环的话，首先查找RUNNABLE的线程。在多线程环境下使用HashMap导致的死循环问题。



**其他**

1. 画一下你们的系统架构图
2. 说一说你们系统有哪些模块，模块之间是怎么通信的
3. 如何与一个算法工程师配合工作？
