## Common Interview Q&A

**消息队列**

1. MQ的主要有哪些作用(包括使用场景)

   异步、削峰填谷、解耦

2. MQ的技术选型

3. MQ如何保证高可用性

   kafka的高可用依赖于多个replica实现，选举出一个leader对外提供服务，其他的partition只同步数据，当leader宕机时，就会重新进行选举。

4. MQ的重复消费该如何解决

   * 在下游消费者接口中保持幂等性，即使消息重复也不会有问题

5. MQ的消息丢失该如何解决

   * 生产者消息丢失：启用mq ack配置，当mq回馈确认消息成功才算发送成功，否则就进行重试。
   * mq消息丢失：开启mq持久化消息配置。kafka可以设置整个集群确认同步后才返回ack，否则就无限重试。
   * 消费者消息丢失：配置手动提交offset，消费失败则mq重发，直到接收到消费者的ack。

6. MQ的消息顺序性如何保证

   * 消费者使用一个partition/ queue进行消费，并按一定的规则把需要保证顺序的数据路由到特定的partition/queue中，由单独的一个消费者消费。

7. MQ的架构设计

   

**分布式缓存**

1. redis和memcache的区别

   * 线程模型不同，redis是单线程，memcache是多线程模型
   * redis支持持久化，memcache不支持持久化
   * redis支持的数据类型更丰富，memcache只支持k,v类型

2. redis的线程模型

   单线程IO多路复用

3. redis支持哪些数据结构

   String、Set、List、Zset、hash

4. redis的过期策略

5. 如何保证redis的高可用

6. redis的主从复制

7. redis的哨兵机制

   - Redis 使用一组哨兵（Sentinel）节点来监控主从 Redis 服务的可用性。

   - 一旦发现 Redis 主节点失效，将选举出一个哨兵节点作为领导者（Leader）。

   - 哨兵领导者再从剩余的从 Redis 节点中选出一个 Redis 节点作为新的主 Redis 节点对外服务。

     选举主节点的优先级：健康度 —> 从节点优先级 —> 数据偏移量 —> runid

8. redis的持久化方式

   * aof 通过记录操作日志来进行持久化
   * rdb 通过直接记录数据快照来进行持久化

9. LRU算法

10. 数据库与缓存双写一致性
    * Cache Aside Pattern，读数据的时候，先从缓存中读取，缓存中不存在，则再从数据库中读取，并插入到缓存中。更新缓存时，先删除缓存，再更新数据库。如果先更新数据库的话，若之后删除缓存失败，会导致后面的请求读到的数据仍然是旧的。为什么不是更新缓存而是删除缓存，因为如果更新缓存的话，假如写操作的频率非常高，那么更新缓存的频率也非常高，而在此期间读操作可能只有一次，改成删除操作的话，那么只有在读这一次的时候才会更新缓存，大大降低了缓存的更新频率。在高并发环境下，当写操作未完成数据库更新时，由于读操作的线程未命中缓存，读取了数据库中的旧值，并更新到了缓存中，导致数据过期。这种情况下，需要在内存中维护一个更新队列，将写操作和读操作全部放入，并一一执行，即可保证一致性，
    * 优化点：对同一对象的多个读操作的更新请求可以合并。
    * 缺点：写操作数量庞大的时候可能导致读操作长时间阻塞。



**API网关的设计**

1. 网关的使用场景
2. 网关设计需要考虑的因素
   * 负载均衡
   * 限流
   * 黑名单
   * 路由
   * 监控



**数据库相关**

1. 数据库引擎MyIsam和InnoDB的区别

   innodb支持事务，支持外键，使用聚集索引，支持行级锁，innodb要求表必须有主键，如果没有主键则会生成一个6字节的rowid，innodb的索引和数据都存放在叶子节点。InnoDB不仅缓存索引信息，还会缓存数据信息。其将数据文件按页读取到缓冲池，然后按最近LRU算法来更新数据。

   myisam不支持事务，不支持外键，使用非聚集索引，支持表级锁，myisam的索引和数据是分离的。

2. 分库分表
   * 水平拆分
   * 垂直拆分
   * 分库分表的数据迁移
   * 相关的中间件：Mycat, sharding-jdbc

3. 如何保证主从数据库的一致性？

   1. 在主库事务提交的时候，同时发起两个操作，操作一是将日志写到本地磁盘，操作二是 将日志同步到从库并确保落盘
   2. 主库此时等待两个操作全部成功返回之后，才返回给应用程序，事务提交成功
   3. pt-table-sync 数据库不同步时的修复工具

4. 分库分表后id主键的生成策略

   - 对外提供服务的算法：使用snowflake算法：时间戳+机房号+机器号+序列号；

   - 客户端生成的算法： mongodb的ObjectId生成算法：Unix时间戳+机器号+进程号+随机数。无锁，使用CAS来保证数据不重复。

     以上两种算法都是单机递增，全局唯一

5. 慢查询优化

6. mvcc

   在InnoDB中，每一行都有2个隐藏列DATA_TRX_ID和DATA_ROLL_PTR

   当sql语句在执行时会产生一个ReadView，ReadView中存储了事务链表中的最小事务uid和最大事务lid。当隔离级别为rr时，该事务链表中的所有数据都是不可见的，uid和lid保持一致即可。当隔离级别为rc时，uid和lid的所有数据对其都是可见的。

7. 数据库的三大范式

   * 所有字段均不可再次拆分。
   * 建立在第一范式的基础上，所有字段必须依赖于主键
   * 任何非主属性不得依赖于其他的非主键属性

8. 数据库异构

9. 字段冗余设计方案

10. 如何实现数据查询时加锁

   在SELECT语句中添加FOR UPDATE，即给需要读取的数据添加排他锁，等待更新事务完成后读取其最新内容。

11. 事务的隔离级别

    * read committed 可以读取到当前资源的最新commit数据
    * repeatable read 当事务开始后，该事务读取到的数据始终是不变的，即其他线程的事务操作对该事务不可见。
    * read uncommit 可获取其他事务未提交的数据，会产生脏读，一般不使用。(除非使用场景对性能的要求很高，并且可以容忍脏读)
    * serialize 最高隔离级别，串行读写，读写会互相阻塞

12. ACID

    * A：atomic 原子性
    * C：consistency 一致性
    * I：isolation  隔离性
    * D: duration 持久性

13. 幻读、脏读、不可重复读

    * 幻读：由于其他事务的更新操作，在某次事务中的对同一资源的两次读取结果的数量不一样（针对insert和delete）。
    * 脏读：读取到了其他事务未提交的数据
    * 不可重复读：由于其他事务的更新操作，在某次事务中的对同一资源的两次读取结果不一样（针对update）。

14. sql语句的常见优化策略：

    1. 表字段应尽量避免null字段的出现，null值很难查询优化且占用额外的索引空间。
    2. 用枚举或整数类型来代替字符串。
    3. 使用整型来存储ip
    4. 有针对性地创建索引，可以用EXPLAIN来查看使用了索引还是全表扫描。
    5. 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
    6. 对于值分部稀少的字段不适合建立索引
    7. 不使用外键，通过程序来保证约束
    8. 使用IN而不使用OR，OR的时间复杂度为O(n)而IN的时间复杂度为O(logn)
    9. 避免使用select *，指明需要查询的字段
    10. 使用limit来限制查询出来的条目数
    11. 不要在where语句的条件中进行计算，会导致全表扫描
    12. 开启慢查询日志，对日志中的异常sql进行排查和优化

15. 数据量剧增后的一般优化思路：

    1. 优化sql语句
    2. 使用缓存
    3. 主从复制，读写分离
    4. 根据业务进行垂直拆分
    5. 水平拆分

16. 索引覆盖

    如果一个索引包含(或覆盖)所有需要查询的字段的值，称为‘覆盖索引’。即只需扫描索引而无须回表。只扫描索引而无需回表的优点：

    1. 索引条目通常远小于数据行大小，只需要读取索引，则mysql会极大地减少数据访问量。
    2. 因为索引是按照列值顺序存储的，所以对于IO密集的范围查找会比随机从磁盘读取每一行数据的IO少很多。
    3. 一些存储引擎如myisam在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用
    4. innodb的聚簇索引，覆盖索引对innodb表特别有用。(innodb的二级索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询)



**JVM相关**

1. 类加载机制

2. 几种常见的垃圾回收器G1，CMS等

   * CMS：采用标记清除算法，会产生内存碎片。主要流程为：初始标记 -> 并发标记 -> 重新标记 -> 并发清理 ->重置线程
   * G1：采用标记整理算法，不会产生内存碎片。主要流程为：初始标记 -> 并发标记 -> 最终标记 -> 筛选回收 (依靠筛选回收，G1可以满足用户预期的清理时间)，G1的内存模型也略有不同，堆内存会被切分成为很多个固定大小区域（Region），每个是连续范围的虚拟内存。每个虚拟内存映射了年轻代，老年代，巨型代，幸存代不同的空间类型。

3. 垃圾回收算法：标记清除，复制算法，标记整理算法

4. JVM的内存模型

   线程共享的有：堆内存，方法区(元空间)

   线程私有：虚拟机栈，本地方法栈，程序计数器

5. 双亲委派模型

   * 当类加载器加载类的时候，首先会将该类委托给父类进行加载，如果父类加载不了，再由自己进行加载。这样的好处是可以保证jvm中的类不被外部的同名类侵染，有利于虚拟机安全。
   * jdk提供了三种类加载器，BootstrapClassLoader，ExtentionClassLoader，AppClassLoader。前两种类加载器分别用于加载jvm基础类和扩展类，第三种才是用于加载用户定义的类。
   * 双亲委派模型的破坏：tomcat破坏了双亲委派模型：1. 为了加载同一个类的不同版本；2. 为了jsp的热更新热部署。一般的破坏实现方式是在Thread中设置自定义的contextClassLoader。

6. 当执行 ``` Test test = new Test() ``` 的时候，发生了什么？

   * 首先jvm会去查找Test类是否已经加载，如果没有则加载Test类
   * 在确认类已经加载完成后，jvm对该对象进行内存分配，主要有两种方式：
     * 指针碰撞：适用于内存比较规整的情况，jvm维护了一个用于指示已使用内存和空闲内存的指针，此时会将空闲一侧的内存分配出来。
     * 空闲列表：jvm维护了一个内存碎片的列表，此时会将大小合适的内存碎片分配出来；
     * 对于对象并发创建时，有两种方案，CAS和TLAB，TLAB是在Eden预留了一部分内存空间，当预留空间不足时，再进行CAS分配内存。
   * 在完成内存分配后，jvm对test对象设置零值
   * 在设置零值完成后，jvm开始设置对象头：包括锁信息，hash值，类信息
   * 在对象头设置完成后，执行init方法（由开发人员编写的逻辑）。





**数据结构与算法相关**

1. 快速排序算法的实现

   首先，选定任意一个节点，将比其小的数据放到其左边，将比其大的数据放到右边。将此称为一次排序。

   然后再对左边和右边的数据分别进行上述排序，直至整个数组排序完成。

2. 希尔排序的实现

3. 红黑树，二叉树相关的原理

4. 跳表的相关原理和实现

   跳表最底层维护了所有数据的链表，每高一级大约减少一半（由插入时的高阶节点生成算法决定）的数据，每个节点都有指向下一级的指针，它多存储了一倍的空间，时间复杂度约为log(n)

5. B树和B+树

6. Mysql的存储结构为何选择B+树而不是B树或者二叉树？

   二叉树的查询效率很高，时间复杂度为O(log(n))，但是由于其节点数只有2，当数据量非常庞大的时候，树的深度会非常深，一旦查询深度过深，需要多次重新定位文件，导致查询效率低下。B树解决了树深度过深的问题，而且它的数据直接存储在每个节点中，但是需要遍历数据时必须进行中序遍历，导致效率低下。B+树的非叶子节点只存储索引，所有数据都存储在叶子节点中，且每个叶子节点都有指向下一个叶子节点的指针，当需要对数据进行遍历时，只要遍历叶子节点即可。



**java基础**

1. HashMap的原理

2. JUC相关工具

   1. ConcurrentHashMap

      1.7中使用segment分段锁。每个segment都持有一部分bucket，在初始化的时候可以指定segment的数量，但是之后不支持segment数组扩容。ConcurrentHashMap的扩容就是对segment内部的bucket进行扩容，每次扩大一倍。

      1.8中使用Entry为锁，扩容时采用多段多线程分别扩容（也有可能最终执行扩容的是同一个线程）的方法（transfer）。

   2. CountDownLatch

      这是一个异步转同步的工具，通过一个总的任务计数递减来控制异步转同步的时机。

   3. Semaphore

      总共10个permits，进来一个线程，就拿走一个，拿完了，其他线程就不能进来，只能等待拿到permit的线程，释放permit，这时候其他线程才有机会进去。

   4. CyclicBarrier

      CyclicBarrier会设置一道屏障，当线程到达该屏障时，必须等待其他所有线程到达该屏障（调用CyclicBarrier.await()方法），才可以继续执行下去。

3. List，Set

4. 线程池的原理和执行流程

5. synchronize的三种锁

   * 偏向锁：该等级的锁认为只有一个线程会来获取和执行，在线程第一次进入的时候会通过cas来设置锁标记，并设置线程id，执行完成后不会更改；当线程第二次进入时，如果发现当前线程id和自己相同，则不再更改所标记，直接进入执行。如果发现线程id不同，则升级为轻量级锁。

   * 轻量级锁：该等级的锁在线程进入时会通过cas来设置锁标记，退出时再通过cas将锁标记取消。如果cas失败，则会升级为重量级锁。适用于多线程执行时间错开的场景。

   * 重量级锁：该等级的锁在线程进入时，如果无法获取到锁，便会立刻进入阻塞状态，等待持有该锁的其他线程唤醒。

6. synchronized和ReentrantLock，死锁产生的场景

   1.5以前synchronized通过获取底层的对象监视器(monitor，依赖于底层操作系统的mutex Lock)来进行加锁，通过查看字节码可以发现monitorenter和monitorexit指令，1.5以后进行了非常大的优化，产生了三种不同级别的锁：偏向锁，轻量级锁，重量级锁。

7. jdk1.8中的新api（Optional，Stream，lamda表达式等等）

8. AQS(抽象队列同步)

   * AQS封装了一套多线程访问共享资源的同步器框架，它的模板逻辑是这样的：

     tryAcquire -> 失败则放入到等待队列中 -> 排队等待唤醒 -> 唤醒后尝试获取资源(失败则回去获取安全位置并继续排队等候) -> 成功则认为获取锁成功 -> 执行临界代码

   * ReentrantLock中的公平锁和非公平锁就是利用AQS实现的。

     * 公平锁重写的tryAcquire方法中会判断自己所在队列中是否还有其他线程排在自己前面，如果有，则继续等待；
     * 而非公平锁首先会尝试CAS获取锁，获取失败则通过AQS的模板方法获取。

9. IO，NIO，BIO相关

10. IO多路复用

11. volatile关键字的底层实现

12. ThreadLocal类的使用与原理

13. HashMap在并发环境下可能会出现什么问题

    1.7可能会出现环形链表，HashMap在进行rehash的时候，如果发生了扩容，会将一个bucket里面的链表进行重新分发。分发后的链表顺序会倒置（1.7，1.8版本的jdk是在链表末端插入元素的）。如果有两个线程同时进行rehash，查阅源码

    ``` java
    do {
        Entry<K,V> next = e.next; // <--假设线程一执行到这里就被调度挂起了
        int i = indexFor(e.hash, newCapacity);
        e.next = newTable[i];
        newTable[i] = e;
        e = next;
    } while (e != null);
    ```

    可知，在此过程中维护了两个指针e和next，导致了环形链表的出现。

    1.8可能会导致数据丢失

14. aba问题

    在cas过程中可能会出现aba问题，解决方法是在更新的时候对数据添加版本号。AtomicMarkableReferencek就提供了这样的功能。

15. volatile为何不能保证原子性

    volatile++其实执行了三步操作：1. 从主内存中读取数据到工作内存；2. 对数据进行自增处理；3. 将数据写回到主内存。当两个线程都执行完了第二步的时候，此时线程1先将数据写回到主内存，但线程2已经完成了自增操作，不会再从主内存中读取最新数据，于是便会将无效的数据写到主内存中。



**框架相关**

1. Spring的生命周期

2. Spring的核心，IOC和AOP

3. Spring用到的设计模式
   * 单例模式
   * 抽象工厂
   * 样板方法
   * 观察者模式
   * 代理模式

4. Spring是如何解决循环引用的 ？

   * setter循环依赖：对于setter注入造成的依赖是通过Spring容器提前暴露刚完毕构造器注入但未完毕其它步骤（如setter注入）的Bean来完毕的，并且仅仅能解决单例作用域的Bean循环依赖
   * 构造器循环依赖：无法解决，会抛出BeanCurrentlyInCreationException。

5. Springboot和Spring的对比

6. Springboot的内置web容器

7. Springboot的思想：约定大于配置

8. SpringCloud的注册中心

9. SpringCloud的配置中心

10. SpringCloud的网关

11. SpringCloud的熔断器

12. Dubbo相关知识
    * Dubbo的服务调用依赖于底层的RpcProxy，默认使用netty，性能高于基于Http调用的SpringCloud。

    * Dubbo的十层架构：
      1. service：由用户实现的接口层
      2. config：Provider和Consumer的配置
      3. proxy：代理生成的Proxy和Invoker类(实际的调用方和被调用方)
      4. registry：封装服务地址的注册与发现
      5. cluster：封装多个提供者的路由及负载均衡，并桥接注册中心
      6. monitor：RPC调用次数和调用时间监控
      7. protocol：封装RPC调用，以Invocation和Result为中心
      8. exchange：封装请求响应模式，同步转异步
      9. transport：抽象mina和netty为统一接口，以Message为中心
      10. serialize：封装序列化的方式

    * Dubbo的服务治理：

      1. 服务调用链路
      2. 服务降级
      3. 服务鉴权
      4. 服务监控
      5. 服务的超时重试

    * Dubbo的SPI扩展

      实现Dubbo提供的SPI接口后，打成jar包，放到META-INF/services/下面并配置key=com.xxx.xxx.xxx，在调用代码中配置相关的key，即可实现Dubbo的SPI扩展

**分布式相关**

1. CAP理论以及相关实践

2. BASE理论

3. 分布式事务XA，2PC，3PC，TCC，本地消息表
   * XA：单机对处于同一事务的多种资源处理时使用，在执行业务逻辑前打开所有资源的事务，成功后统一commit，失败则全部rollback。
   * 2PC：分为prepare和commit两个阶段，prepare阶段协调者会询问参与者是否可以提交，参与者认为可以则将undo和redo信息写到事务日志中。commit阶段一旦任意参与者失败则协调者调用undo进行rollback，缺点：所有回滚逻辑均需要手动实现，非常麻烦，且存在参与者阻塞协调者的问题。
   * 3PC：分为canCommit，preCommit，doCommit三个阶段，参与者在preCommit阶段将undo和redo信息写入到事务日志中。在doCommit阶段出现异常则协调者调用undo进行rollback。缺点：所有回滚逻辑均需要手动实现，非常麻烦。协调者如果宕机，在一定时间内参与者会自动提交事务
   * 本地消息表：在系统A持久化业务数据的同时插入一个本地消息表并置为待消费状态，同时通过mq发送消息给系统B，消息B消费完成后回调系统A的通知接口(或可以使用zookeeper做监听)，将消息置为已消费状态。系统A需要维护一个轮询待消费状态消息的线程，将超时待消费消息重新发给B进行消费，如果多次后仍然失败，需要进行回滚。系统B必须保证消息消费的幂等性。

4. 分布式锁的实现：

    * redis的一般实现：使用SETNX命令来对同一个key设置随机值，设置成功则认为获取锁成功；释放锁时只需要删除该key即可，删除时需判断是否为获取锁时设置的随机值，使用定时轮询来获取锁。
    * redis的RedLock实现：上述分布式锁如果是单机redis存在单点故障问题，使用主备则存在一致性问题。RedLock则是对redis集群所有实例发送加锁命令，只要设置成功的数量超过一半，则认为设置成功。
    * zookeeper的实现：使用创建临时顺序节点来获取锁，当设置节点的序列号为最小时，说明获取分布式锁成功；获取失败则对成功的节点注册监听（这是非公平锁的做法，要实现公平锁只需要注册上一个序列号节点的监听即可）。释放锁时，只需要删除节点即可，此时注册了监听的客户端会收到zk的通知，并再次尝试获取锁。

5. 使用redis实现的分布式锁，会有什么问题？

   1. setnx和expire的非原子性

      使用LUA脚本

   2. 超时后使用del 导致误删其他线程的锁

      在获取锁时存入当前的线程id，删除时判断是否为自己线程所持有的锁。(原子性问题可以用LUA脚本解决) 如下：
      ``` lua
      if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end 
      ```

   3. 由于超时时间的设置，仍然存在出现并发的可能性

6. Paxos算法

    使用奇数个节点的acceptor，即使有多个coordinate，也可以通过多出来的acceptor通过提议。假如两个coordinate的acceptor相同，那么比较他们的贿选数值大小即可。



**运维相关**

1. docker的概念和使用
2. Linux的常用指令



**高并发相关**

1. 如何设计一个高并发的系统？
   * 拆分系统，将系统根据业务拆分成多个模块，对压力较大的模块做集群；
   * 使用分布式缓存，缓解数据库压力
   * 使用MQ进行削峰
   * 动静资源分离
   * 数据库读写分离
   * 使用分布式搜索引擎



**网络相关**

1. http的三次握手和四次挥手
2. TCP和UDP
3. 当我们在浏览器访问一个网址的时候，发生了什么
   1. 浏览器解析URL，抽出域名字段
   2. DNS服务器对域名进行解析（浏览器缓存，系统缓存，路由器缓存），并映射到具体的ip地址
   3. 浏览器与服务器建立TCP连接
   4. 浏览器与服务器传输数据
   5. 浏览器渲染页面



**线上故障排查相关**

1. cpu 100%

   使用jstack工具dump出问题的服务器的栈信息，死循环的话，首先查找RUNNABLE的线程。在多线程环境下使用HashMap导致的死循环问题。



**其他**

1. 画一下你们的系统架构图

2. 说一说你们系统有哪些模块，模块之间是怎么通信的

3. 如何与一个算法工程师配合工作？

4. 系统是如何拆分的，按照什么粒度？

5. 做过哪些优化？

   * sql优化方面
   * jvm方面的优化
   * 多线程优化
   * 第三方组件扩展

6. 自我介绍

   我叫吴一鸣，2015年7月毕业于江南大学。毕业后在上汽大通工作，期间主要负责了工程师工具网站的模块和C2B展示模块的开发。17年4月于杭州风先生入职，并且工作至今，目前主要负责核心订单模块，配送员管理模块以及一些底层公用组件模块的开发，如线程池组件，算法组件，集合组件，数据库组件，国际化组件等等。平时比较喜欢看一些技术博客，也会练练硬笔书法，玩玩游戏和球类运动等。目前在本公司已经工作两年多，感觉技术上的提升遇到了瓶颈，因此想要出来到一个平台更大，技术更加先进完备的环境来提升自己。
